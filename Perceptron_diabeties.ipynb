{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabeties classification using perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Dataset : (768, 9)\n",
      "The features of the dataset : ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
      "Labels of the dataset :  Outcome\n"
     ]
    }
   ],
   "source": [
    "#loading dataset\n",
    "DB = pd.read_csv('dataset/diabetes.csv') #8 inputs 1 output\n",
    "print(\"The Shape of the Dataset :\",DB.shape)\n",
    "print(\"The features of the dataset :\",list(DB.keys())[:-1])\n",
    "print(\"Labels of the dataset : \", list(DB.keys())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a perceptron class\n",
    "class Perceptron:\n",
    "\tdef __init__(self,feature_size) -> None:\n",
    "\t\tself.feature_size=feature_size\n",
    "\t\tself.weights= np.random.random(feature_size)\n",
    "\t\tself.bias = random()\n",
    "\t\t\n",
    "\tdef split_standardise(self,DB,split_size,output_scale=True):\n",
    "\t\ttrain_ratio = math.floor(DB.shape[0]*split_size)\n",
    "\t\tfor i in DB.keys()[:-1]:\n",
    "\t\t\tstd = DB[i][:train_ratio].std()\n",
    "\t\t\tmean =  DB[i][:train_ratio].mean()\n",
    "\t\t\tDB[i]=(DB[i]-mean)/std\n",
    "\t\tif output_scale: \n",
    "\t\t\tDB.loc[(DB.Outcome ==0)] = -1\n",
    "\t\ttrain = DB.iloc[:train_ratio,:]\n",
    "\t\ttest = DB.iloc[train_ratio:,:]\n",
    "\t\tY_train = train.Outcome\n",
    "\t\tX_train = train[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\t\tY_test = test.Outcome\n",
    "\t\tX_test = test[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\t\treturn X_train.to_numpy(),X_test.to_numpy(),Y_train.to_numpy(),Y_test.to_numpy()\n",
    "\n",
    "\tdef predict(self,X):\n",
    "\t\tpred = self.bias\n",
    "\t\tfor i in range(self.feature_size):\n",
    "\t\t\tpred += (self.weights[i]*X[i])\n",
    "\t\treturn 1 if pred>0 else 0 #sign function\n",
    "\t\n",
    "\tdef activationFunction(self, inputs):\n",
    "\t\tz = np.dot(inputs, self.weights) + self.bias # z = W * X \n",
    "\t\treturn np.where(z > 0, 1, -1) # ACTIVATION FUNCTION\n",
    "\n",
    "\tdef training_function(self,DB,l_rate,n_epoch,test_size,op_scl=True):\n",
    "\t\tX_train, X_test, Y_train, Y_test =  self.split_standardise(DB,1-test_size,op_scl)\n",
    "\t\tprint(f'Commencing training with parameters \\nLearning rate : {l_rate}\\nNo. of Epochs : {n_epoch}\\nTrain-Test split : {(1-test_size)*100}:{(test_size*100)}')\n",
    "\t\tloss=[]\n",
    "\t\ttrain_acc = []\n",
    "\t\ttest_acc = []\n",
    "\t\tfor epoch in range(n_epoch):\n",
    "\t\t\t#print(f'Epoch {epoch}/{n_epoch}\\n','__'*40)\n",
    "\t\t\tY_pred = self.activationFunction(X_train)\n",
    "\t\t\terror = Y_train - Y_pred\n",
    "\t\t\tself.weights = self.weights + l_rate*np.dot(error,X_train)\n",
    "\t\t\tself.bias = self.bias + l_rate*sum(error)\n",
    "\t\t\tloss.append(np.dot(error.T,error)/X_train.shape[0])\n",
    "\t\t\tY_pred_train = self.activationFunction(X_train)\n",
    "\t\t\ttrain_acc.append(self.Accuracy(X_train,Y_train))\n",
    "\t\t\ttest_acc.append(self.Accuracy(X_test,Y_test))\n",
    "\t\tprint(f\"weight={self.weights}\\nbias={self.bias}\")\n",
    "\t\tprint(f\"Training Accuracy : %.3f \\tTesting Accuracy : %.3f\" % (train_acc[-1]*100,test_acc[-1]*100))\n",
    "\n",
    "\tdef Accuracy(self,X,Y):\n",
    "\t\ttotal_items = len(Y)\n",
    "\t\tcount_TP=0\n",
    "\t\tcount_TN=0\n",
    "\t\tcount_FP=0\n",
    "\t\tcount_FN=0\n",
    "\t\tfor i, data in enumerate(X):\n",
    "\t\t\tif Y[i]==1:\n",
    "\t\t\t\tif self.predict(data)==1:\n",
    "\t\t\t\t\tcount_TP+=1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcount_FN+=1\n",
    "\t\t\telse:\n",
    "\t\t\t\tif self.predict(data)==1:\n",
    "\t\t\t\t\tcount_FP+=1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcount_TN+=1\n",
    "\t\treturn (count_TN+count_TP)/total_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment1 \n",
    "With Training data: Testing data ratio = 70:30\n",
    "\n",
    "Without output scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.001\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 0.09002769  0.13680061 -0.04667713 -0.10169705 -0.05010091  0.0525157\n",
      "  0.02447253  0.11654716]\n",
      "bias=0.21849251110760068\n",
      "Training Accuracy : 54.190 \tTesting Accuracy : 55.411\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.001\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.005\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[0.68873676 1.10522705 0.05176866 0.38389118 0.69542896 0.7438229\n",
      " 0.46940075 0.62850233]\n",
      "bias=0.2731690905442897\n",
      "Training Accuracy : 68.715 \tTesting Accuracy : 71.861\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.005\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.01\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 1.21143371  1.86661344 -0.32249318  0.30351448  1.17296221  1.51291487\n",
      "  0.82073386  1.08854491]\n",
      "bias=-0.0669861332869428\n",
      "Training Accuracy : 72.253 \tTesting Accuracy : 73.593\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.05\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 4.19806247  8.7671717  -2.77441938  0.16535897  3.2185088   5.95790521\n",
      "  2.93978283  3.33346199]\n",
      "bias=-2.5199891296112504\n",
      "Training Accuracy : 73.371 \tTesting Accuracy : 78.788\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.05\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.1\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 8.55043539 16.82056817 -7.12285989 -0.32758994  6.20790772 10.62428539\n",
      "  5.14323581  6.02628872]\n",
      "bias=-4.879873462809524\n",
      "Training Accuracy : 74.115 \tTesting Accuracy : 77.922\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.5\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 38.83604871  81.07885289 -32.50476036  -8.90410939  10.83284865\n",
      "  48.4920103   25.85163823  21.13504108]\n",
      "bias=-33.66288295565056\n",
      "Training Accuracy : 74.302 \tTesting Accuracy : 79.654\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "l_rate = 0.5\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment2 \n",
    "With Training data: Testing data ratio = 80:20\n",
    "\n",
    "Without output scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.001\n",
      "No. of Epochs : 100\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[0.13753577 0.25853279 0.02116589 0.10674856 0.18806861 0.20506054\n",
      " 0.12853823 0.12734485]\n",
      "bias=0.06350843744048382\n",
      "Training Accuracy : 69.707 \tTesting Accuracy : 68.182\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.001\n",
    "n_epoch = 100\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.005\n",
      "No. of Epochs : 100\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 0.81162337  1.2364628  -0.03163058  0.47547837  0.83280921  0.93772944\n",
      "  0.62584004  0.73295581]\n",
      "bias=0.19539260769120292\n",
      "Training Accuracy : 69.381 \tTesting Accuracy : 71.429\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.005\n",
    "n_epoch = 100\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.01\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[1.36755904 2.70002041 0.45075524 1.03871491 2.15511928 2.27748255\n",
      " 1.37170234 1.35183022]\n",
      "bias=0.610306770304677\n",
      "Training Accuracy : 69.544 \tTesting Accuracy : 68.831\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.05\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 5.1441065   9.80489505 -2.54249039  0.0387423   3.37272756  6.04616547\n",
      "  3.53065425  4.60247078]\n",
      "bias=-3.433627061542177\n",
      "Training Accuracy : 74.593 \tTesting Accuracy : 77.922\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.05\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.1\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[15.64671595 23.60802004 -1.04911032  5.25349348 15.09327476 16.13645723\n",
      " 10.19258053 15.15591123]\n",
      "bias=-0.12803134043289788\n",
      "Training Accuracy : 71.173 \tTesting Accuracy : 72.078\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.5\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 50.93828302  91.7705921  -28.14819609  -3.97038621  22.29757693\n",
      "  54.68593788  29.32763366  41.13745555]\n",
      "bias=-39.29342300439271\n",
      "Training Accuracy : 75.244 \tTesting Accuracy : 77.273\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.5\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 \n",
    "With Training data: Testing data ratio = 70:30\n",
    "\n",
    "With output scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.001\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 0.38046538  0.56767863  0.18202748  0.37849634 -0.30414137  0.70384424\n",
      "  0.40696812  0.37956684]\n",
      "bias=0.7829723628804289\n",
      "Training Accuracy : 97.952 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.001\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.005\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[0.76210743 0.69492335 0.24796744 0.0653665  0.12119048 0.45630677\n",
      " 0.90174979 0.06191645]\n",
      "bias=0.2689315460699123\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 99.134\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.005\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.01\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 0.47345683  0.60007557 -0.00498111  0.11912942  0.00216366  0.42232565\n",
      "  0.27998426  0.11606856]\n",
      "bias=0.7816322957889423\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.05\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 0.81346446  0.82373727 -0.07865036  0.24077155  0.27154554  0.75410064\n",
      "  0.52243178  0.9628307 ]\n",
      "bias=1.453012476111476\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.05\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.1\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 2.23348801  1.91210519 -2.17750656 -0.22621851  0.5261242   2.14558509\n",
      "  1.23476661  2.40249685]\n",
      "bias=4.210490746601837\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.5\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[267.61153482 316.49307944 101.6331506  198.34651361 218.4416749\n",
      " 349.20329585 245.22466853 286.24603799]\n",
      "bias=-183.48574679801916\n",
      "Training Accuracy : 98.883 \tTesting Accuracy : 99.134\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "l_rate = 0.5\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4 \n",
    "With Training data: Testing data ratio = 80:20\n",
    "\n",
    "With output scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.001\n",
      "No. of Epochs : 100\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 0.41110189  0.50121471  0.25153184  0.6213165  -0.00276923  0.20851405\n",
      "  0.4623573   0.56020385]\n",
      "bias=0.8774516811081744\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 99.351\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.001\n",
    "n_epoch = 100\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.005\n",
      "No. of Epochs : 100\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 0.13337249  0.41738024  0.20145671 -0.0473685   0.56839405  0.40656199\n",
      "  0.22799546  0.84193947]\n",
      "bias=0.3305673501627264\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.005\n",
    "n_epoch = 100\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.01\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[0.25896569 1.03096496 0.460928   0.17442262 0.77087175 0.88846963\n",
      " 0.52396821 0.53361368]\n",
      "bias=0.761667088563869\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.05\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[0.29400264 0.76135492 0.07635762 0.37344552 0.105126   0.02160573\n",
      " 0.79656545 0.68326317]\n",
      "bias=0.8570155463678266\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 99.351\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.05\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.1\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 0.15311941  0.87415196 -0.29250929  0.2485046   0.86035048  0.56099345\n",
      "  0.72508047  0.48636445]\n",
      "bias=1.180310523323185\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.5\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[312.66941674 357.19302205 132.80303822 213.82514672 249.57774888\n",
      " 387.14731992 295.94022961 344.5831562 ]\n",
      "bias=-225.24841376644162\n",
      "Training Accuracy : 99.186 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.5\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('C_AIML_Ass1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00302b6afa1654c2c690cbefd42db25779f584dfc8f26178b0b8eb9ee0f07dd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
