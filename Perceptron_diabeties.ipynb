{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabeties classification using perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Dataset : (768, 9)\n",
      "The features of the dataset : ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
      "Labels of the dataset :  Outcome\n"
     ]
    }
   ],
   "source": [
    "#loading dataset\n",
    "DB = pd.read_csv('dataset/diabetes.csv') #8 inputs 1 output\n",
    "print(\"The Shape of the Dataset :\",DB.shape)\n",
    "print(\"The features of the dataset :\",list(DB.keys())[:-1])\n",
    "print(\"Labels of the dataset : \", list(DB.keys())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a perceptron class\n",
    "class Perceptron:\n",
    "\tdef __init__(self,feature_size) -> None:\n",
    "\t\tself.feature_size=feature_size\n",
    "\t\tself.weights= np.random.random(feature_size)\n",
    "\t\tself.bias = random()\n",
    "\t\t\n",
    "\tdef split_standardise(self,DB,split_size):\n",
    "\t\ttrain_ratio = math.floor(DB.shape[0]*split_size)\n",
    "\t\tfor i in DB.keys()[:-1]:\n",
    "\t\t\tstd = DB[i][:train_ratio].std()\n",
    "\t\t\tmean =  DB[i][:train_ratio].mean()\n",
    "\t\t\tDB[i]=(DB[i]-mean)/std\n",
    "\t\tDB.loc[(DB.Outcome ==0)] = -1\n",
    "\t\ttrain = DB.iloc[:train_ratio,:]\n",
    "\t\ttest = DB.iloc[train_ratio:,:]\n",
    "\t\tY_train = train.Outcome\n",
    "\t\tX_train = train[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\t\tY_test = test.Outcome\n",
    "\t\tX_test = test[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\t\treturn X_train.to_numpy(),X_test.to_numpy(),Y_train.to_numpy(),Y_test.to_numpy()\n",
    "\n",
    "\tdef predict(self,X):\n",
    "\t\tpred = self.bias\n",
    "\t\tfor i in range(self.feature_size):\n",
    "\t\t\tpred += (self.weights[i]*X[i])\n",
    "\t\treturn 1 if pred>0 else 0 #sign function\n",
    "\t\n",
    "\tdef activationFunction(self, inputs):\n",
    "\t\tz = np.dot(inputs, self.weights) + self.bias # z = W * X \n",
    "\t\treturn np.where(z > 0, 1, -1) # ACTIVATION FUNCTION\n",
    "\n",
    "\tdef training_function(self,DB,l_rate,n_epoch,test_size):\n",
    "\t\tX_train, X_test, Y_train, Y_test =  self.split_standardise(DB,1-test_size)\n",
    "\t\tprint(f'Commencing training with parameters \\nLearning rate : {l_rate}\\nNo. of Epochs : {n_epoch}\\nTrain-Test split : {(1-test_size)*100}:{(test_size*100)}')\n",
    "\t\tloss=[]\n",
    "\t\ttrain_acc = []\n",
    "\t\ttest_acc = []\n",
    "\t\tfor epoch in range(n_epoch):\n",
    "\t\t\t#print(f'Epoch {epoch}/{n_epoch}\\n','__'*40)\n",
    "\t\t\tY_pred = self.activationFunction(X_train)\n",
    "\t\t\terror = Y_train - Y_pred\n",
    "\t\t\tself.weights = self.weights + l_rate*np.dot(error,X_train)\n",
    "\t\t\tself.bias = self.bias + l_rate*sum(error)\n",
    "\t\t\tloss.append(np.dot(error.T,error)/X_train.shape[0])\n",
    "\t\t\tY_pred_train = self.activationFunction(X_train)\n",
    "\t\t\ttrain_acc.append(self.Accuracy(X_train,Y_train))\n",
    "\t\t\ttest_acc.append(self.Accuracy(X_test,Y_test))\n",
    "\t\tprint(f\"weight={self.weights}\\nbias={self.bias}\")\n",
    "\t\tprint(f\"Training Accuracy : %.3f \\tTesting Accuracy : %.3f\" % (train_acc[-1]*100,test_acc[-1]*100))\n",
    "\n",
    "\tdef Accuracy(self,X,Y):\n",
    "\t\ttotal_items = len(Y)\n",
    "\t\tcount_TP=0\n",
    "\t\tcount_TN=0\n",
    "\t\tcount_FP=0\n",
    "\t\tcount_FN=0\n",
    "\t\tfor i, data in enumerate(X):\n",
    "\t\t\tif Y[i]==1:\n",
    "\t\t\t\tif self.predict(data)==1:\n",
    "\t\t\t\t\tcount_TP+=1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcount_FN+=1\n",
    "\t\t\telse:\n",
    "\t\t\t\tif self.predict(data)==1:\n",
    "\t\t\t\t\tcount_FP+=1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcount_TN+=1\n",
    "\t\treturn (count_TN+count_TP)/total_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment1 \n",
    "With Training data: Testing data ratio = 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.001\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 0.41310254  0.21941522  0.12199358 -0.16386577  0.60783154  0.46107971\n",
      "  0.57056846  0.08244502]\n",
      "bias=0.9428100806578203\n",
      "Training Accuracy : 98.324 \tTesting Accuracy : 99.134\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.001\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.005\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[0.55248695 0.59939742 0.12530187 0.74027153 0.17230801 0.34503661\n",
      " 0.22583747 0.0911471 ]\n",
      "bias=0.49753993826723303\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 99.134\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.005\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.01\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[0.97071504 0.31771766 0.16072736 0.39224839 0.63613779 0.51080787\n",
      " 0.51931906 0.7926857 ]\n",
      "bias=0.7422885985594913\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 99.567\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.05\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[ 0.82006755  0.84656236 -0.20277785  0.20906657  0.68387186  0.79999708\n",
      "  0.53916014  1.14561698]\n",
      "bias=1.4591550315649267\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.05\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.1\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 70.0:30.0\n",
      "weight=[45.18863416 55.25861809 13.37283764 27.60792941 35.11116019 55.06593247\n",
      " 42.57426248 49.34664605]\n",
      "bias=-43.54248785175261\n",
      "Training Accuracy : 98.883 \tTesting Accuracy : 99.134\n"
     ]
    }
   ],
   "source": [
    "test_size =0.3\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment2 \n",
    "With Training data: Testing data ratio = 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.001\n",
      "No. of Epochs : 100\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[0.97807963 0.46327995 0.33021133 0.16260712 0.21263066 0.8310325\n",
      " 0.2596281  0.9932735 ]\n",
      "bias=0.6410524705721871\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.001\n",
    "n_epoch = 100\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.005\n",
      "No. of Epochs : 100\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[0.28535837 0.36066579 0.32517882 0.30212532 0.58372777 0.50188891\n",
      " 0.28268986 0.54460114]\n",
      "bias=1.0879368309723485\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.005\n",
    "n_epoch = 100\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.01\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[0.91306512 0.66394505 0.2741248  0.32760639 0.80875454 0.98831838\n",
      " 1.02332801 0.47165699]\n",
      "bias=0.7109308817603077\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.01\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.05\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[ 1.19819639  0.96048036 -0.69434712  0.35295869  0.78497009  1.19523655\n",
      "  0.54293261  1.07593855]\n",
      "bias=1.9215471044082033\n",
      "Training Accuracy : 100.000 \tTesting Accuracy : 100.000\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.05\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commencing training with parameters \n",
      "Learning rate : 0.1\n",
      "No. of Epochs : 10\n",
      "Train-Test split : 80.0:20.0\n",
      "weight=[54.28144661 66.05769472 20.1466053  37.54081556 44.14460655 67.22425894\n",
      " 52.69023862 59.34605011]\n",
      "bias=-48.33725031898397\n",
      "Training Accuracy : 99.023 \tTesting Accuracy : 98.701\n"
     ]
    }
   ],
   "source": [
    "test_size =0.2\n",
    "l_rate = 0.1\n",
    "n_epoch = 10\n",
    "#Spliting Testing and Training Data\n",
    "model=Perceptron(DB.shape[1]-1)\n",
    "model.training_function(DB,l_rate,n_epoch,test_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('C_AIML_Ass1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00302b6afa1654c2c690cbefd42db25779f584dfc8f26178b0b8eb9ee0f07dd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
